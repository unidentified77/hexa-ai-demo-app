# ðŸ¤– AI Collaboration Summary

This document is prepared for how AI tools were utilized to accelerate development, improve code quality, and solve technical challenges during the "Hexa - AI Logo Generator" project.

## ðŸ›  Tools Used
* **ChatGPT (OpenAI):** Used for initial case study analysis, roadmap planning, style enhancements to match with the figma design, generation of AI api tests for better development environment.
* **Gemini :** Used for code generation, refactoring, debugging, and styling translations (CSS to React Native). I used gemini to prepare reports by directing with my own words, it saved a lot of time.
* **Claude :** When I could not find a solutions with gemini and chatgpt I used Claude AI but did not get good feedbacks.

## ðŸš€ Usage Workflow & Key Contributions

### 1. Planning & Analysis
* **Case Study Summary:** Initially, I uploaded the case study PDF to ChatGPT to generate a summary. This ensured I didn't miss any critical requirements or hidden constraints before starting.
* **Roadmap Adaptation:** I generated a development roadmap using AI. However, due to an inability to inspect the Figma file on Day 1, I **manually intervened** and adjusted the roadmap. I prioritized backend logic and API integration over pixel-perfect UI in the early stages, diverging from the AI's suggested linear path.

### 2. Backend & Architecture
* **Firestore Rules:** AI helped generate secure Firestore Security Rules to allow read/write access for authenticated anonymous users.
* **API Research & Integration:** I used AI's web browsing capabilities to research free and accessible generative AI APIs. I then used AI to write **isolated Python test scripts** (`test_groq.py`, `test_pollinations.py`) to verify these APIs locally before integrating them into Firebase Cloud Functions.

### 3. Frontend & UI
* **Complex Styling:** I used AI to translate complex Figma CSS properties (specifically the background linear gradients and blur effects) into React Native's `expo-linear-gradient` and `StyleSheet` syntax.
* **Code Readability:** AI was used to refactor large components (like `InputScreen.tsx`) into smaller, readable chunks and to clean up unused imports.

### 4. Debugging
* **Firestore Listeners:** When setting up the real-time `onSnapshot` listener, I encountered connection stability issues. I used AI to analyze my hook dependencies and strategically place `console.log` statements to trace the data flow and fix the synchronization.
* **Layout Stability:** AI assisted in diagnosing a layout shift issue on the "Surprise Me" button by suggesting fixed height constraints.

---

## ðŸ’¡ Example Prompts

Here are a few examples of prompts that yielded high-value results:

> **For Pollinations AI Usage:**
> "Write a Python script using `requests` to send a prompt to the Pollinations.ai API and save the binary response as a PNG file locally. Include error handling for non-200 status codes."

> **Status changes to done but UI did not respond to it**
> "My Firestore `onSnapshot` listener is triggering, but the UI isn't updating immediately when the status changes to 'done'. Here is my `useEffect` hook and state logic. Am I missing a dependency or handling the unsubscribe function incorrectly?"

---

## ðŸ’­ Reflection

### What AI did well
AI was exceptionally good at **boilerplate reduction** and **syntax translation**. For instance, converting raw CSS from Figma into React Native styles saved hours of trial and error. It was also very effective at writing isolated Python scripts to test external APIs (Groq/Pollinations), which allowed me to validate the backend logic without deploying to Firebase constantly.

### What I had to significantly adjust or fix
* **The Roadmap:** AI suggested a linear path starting with UI. I had to manually restructure the entire plan to focus on Backend/API integration first due to initial lack of access to design specs.
* **Async Logic & Listeners:** While AI provided the basic Firestore listener code, it struggled with the specific race conditions and state updates in React Native. I had to manually debug the flow to ensure the "Processing" to "Done" transition was smooth and didn't cause infinite loops.
* **AI Caused Waste of Time:** While developing the project, I was getting an error saying that a string was placed where a boolean was expected and I could not see it when I looked at the code. I tried to solve it using AI and this caused me to waste a lot of time. Later, when I opened a new project from scratch and moved the codes, it worked.
* **Firebase Console** I had to examine the incoming jobs using the firebase console and make changes accordingly.


### Anything deliberately done without AI
* **Architectural Decisions:** The decision to use **Real AI APIs** instead of mock data was a deliberate choice I made to enhance the project scope.
* **Project Configuration:** Setting up the Firebase project, enabling Cloud Functions, and configuring the Expo environment were done manually to ensure correct permissions and region settings.